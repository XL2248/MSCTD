# MSCTD Processed Data/Features

## bpe_ende/bpe_zhen
The two folders `bpe_ende/bpe_zhen` contains training/dev/test sets after bpe processing.

The script `build_sub_dialog_ende.py` in bpe_ende or `build_sub_dialog.py` in bpe_zhen aims to generate subdialog with context length 3.
For example, you can run this as follows (train/dev/test):
```
cd ./bpe_ende
python build_sub_dialog_ende.py train
cd ./bpe_zhen
python build_sub_dialog.py test
```

## ende/deen/enzh/zhen
The four folders `ende/deen/enzh/zhen` contains training/dev/test sets with corresponding dialogue context, which is generated by running the `split_*.py` script of different folders (* means enzh/ende). 
For example, you can run this as follows (train/dev/test):
```
cd ./ende
python split_ende.py train
```
The vocabulary used can be found in corresponding folder (`ende/deen/enzh/zhen`) and you also can generate it by running `build_vocab.py` as follows:
```
cd ./ende
python build_vocab.py training_file ende.bpe32k.vocab4.txt # Note that you need cat train_en.txt and train_de.txt for shared vocabulary for ende.
```
## Image features
### CSV
Following this [procedure](https://github.com/ShannonAI/OpenViDial/blob/main/video_dialogue_model/extract_features/extract_features.md) in [OpenViDial](https://github.com/ShannonAI/OpenViDial), the coarse features extracted by ResNet50 can be downloaded here [CSV features](https://drive.google.com/file/d/1GExHEXCHrImR9EhROP7yzIsG00jBXrCu/view?usp=sharing).
### FOV
Similarly, following this [procedure](https://github.com/ShannonAI/OpenViDial/blob/main/video_dialogue_model/extract_features/extract_features.md) in [OpenViDial](https://github.com/ShannonAI/OpenViDial), the Fine-grained Object-based Visual features extracted by Faster R-CNN can be downleaded here [FOV features](https://drive.google.com/file/d/1DCdIgBnEJegJnFxL5LPO_PpMtXbNxoIs/view?usp=sharing). Note that we only used one object feature due to "the hard limit of 2GB for serializing individual tensors because of the 32bit signed size in protobuf and GraphDef cannot be larger than 2GB". For using more object features, we have tried Iterative training and we are also still exploring this...
